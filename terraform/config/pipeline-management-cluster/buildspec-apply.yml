version: 0.2

env:
  shell: bash

phases:
  install:
    commands:
      - ./scripts/pipeline-common/terraform-install.sh

  pre_build:
    commands:
      - source scripts/pipeline-common/setup-apply-preflight.sh
      - source scripts/pipeline-common/assume-target-role.sh "target account operations"

  build:
    commands:
      - echo "=========================================="
      - echo "Provisioning Management Cluster Infrastructure"
      - echo "=========================================="
      - |
        set -euo pipefail

        echo "Deploying to account: ${TARGET_ACCOUNT_ID}"
        echo "  Region: ${TARGET_REGION}"
        echo "  Alias: ${TARGET_ALIAS}"
        echo ""

        # Configure Terraform backend (state in central account, region detected in pre_build)
        export TF_STATE_BUCKET="terraform-state-${CENTRAL_ACCOUNT_ID}"
        export TF_STATE_KEY="management-cluster/${TARGET_ALIAS}.tfstate"

        echo "Terraform backend:"
        echo "  Bucket: $TF_STATE_BUCKET (central account: $CENTRAL_ACCOUNT_ID)"
        echo "  Key: $TF_STATE_KEY"
        echo "  Region: $TF_STATE_REGION"
        echo ""

        # Resolve REGIONAL_AWS_ACCOUNT_ID (supports both direct values and SSM parameter references)
        RESOLVED_REGIONAL_ACCOUNT_ID="${REGIONAL_AWS_ACCOUNT_ID}"

        # If value is an SSM parameter reference (starts with ssm:/), fetch from Parameter Store
        if [[ "$RESOLVED_REGIONAL_ACCOUNT_ID" =~ ^ssm:/ ]]; then
            SSM_PARAM_NAME="${RESOLVED_REGIONAL_ACCOUNT_ID#ssm:}"
            echo "Resolving SSM parameter: $SSM_PARAM_NAME in region ${TARGET_REGION}"

            RESOLVED_REGIONAL_ACCOUNT_ID=$(aws ssm get-parameter \
                --name "$SSM_PARAM_NAME" \
                --with-decryption \
                --query 'Parameter.Value' \
                --output text \
                --region "${TARGET_REGION}")

            echo "✓ Resolved regional account ID: $RESOLVED_REGIONAL_ACCOUNT_ID"
        fi

        # Validate that REGIONAL_AWS_ACCOUNT_ID is non-empty
        if [[ -z "$RESOLVED_REGIONAL_ACCOUNT_ID" ]]; then
            echo "❌ ERROR: REGIONAL_AWS_ACCOUNT_ID must be provided for region ${TARGET_REGION}"
            echo "   Set this in your management cluster config (either direct account ID or ssm:/path/to/param)"
            exit 1
        fi

        # Set Terraform variables
        export TF_VAR_region="${TARGET_REGION}"
        export TF_VAR_app_code="${APP_CODE}"
        export TF_VAR_service_phase="${SERVICE_PHASE}"
        export TF_VAR_cost_center="${COST_CENTER}"
        export TF_VAR_cluster_id="${CLUSTER_ID:-mgmt-cluster-01}"
        export TF_VAR_regional_aws_account_id="${RESOLVED_REGIONAL_ACCOUNT_ID}"

        # Set repository URL and branch with proper fallback handling for set -u
        # Note: CODEBUILD_SOURCE_VERSION contains S3 artifact location, not git branch
        # Use REPOSITORY_BRANCH (from CodeBuild env vars) or GITHUB_BRANCH instead
        _REPO_URL="${REPOSITORY_URL:-}"
        _REPO_BRANCH="${REPOSITORY_BRANCH:-${GITHUB_BRANCH:-main}}"
        export TF_VAR_repository_url="${REPOSITORY_URL:-https://github.com/${GITHUB_REPOSITORY}.git}"
        export TF_VAR_repository_branch="${_REPO_BRANCH}"

        export TF_VAR_target_account_id="${TARGET_ACCOUNT_ID}"

        # Set enable_bastion variable (default to false if not set)
        ENABLE_BASTION="${ENABLE_BASTION:-false}"
        if [ "$ENABLE_BASTION" == "true" ] || [ "$ENABLE_BASTION" == "1" ]; then
            export TF_VAR_enable_bastion="true"
        else
            export TF_VAR_enable_bastion="false"
        fi

        echo "Terraform variables:"
        echo "  Region: $TF_VAR_region"
        echo "  Target Account: $TF_VAR_target_account_id"
        echo "  Cluster ID: $TF_VAR_cluster_id"
        echo "  Regional AWS Account: $TF_VAR_regional_aws_account_id"
        echo "  Enable Bastion: $TF_VAR_enable_bastion"
        echo "  App Code: $TF_VAR_app_code"
        echo "  Service Phase: $TF_VAR_service_phase"
        echo "  Cost Center: $TF_VAR_cost_center"
        echo "  Repository URL: $TF_VAR_repository_url"
        echo "  Repository Branch: $TF_VAR_repository_branch"
        echo ""

        # Create placeholder Maestro agent secrets in target account (using assumed credentials from pre_build)
        echo "Ensuring Maestro agent secrets exist in account ${TARGET_ACCOUNT_ID}..."

        for SECRET_NAME in "maestro/agent-cert" "maestro/agent-config"; do
            # Check if secret exists (using target account credentials)
            if ! AWS_ACCESS_KEY_ID="$TARGET_AWS_ACCESS_KEY_ID" \
                 AWS_SECRET_ACCESS_KEY="$TARGET_AWS_SECRET_ACCESS_KEY" \
                 AWS_SESSION_TOKEN="$TARGET_AWS_SESSION_TOKEN" \
                 aws secretsmanager describe-secret --secret-id "$SECRET_NAME" --region ${TARGET_REGION} 2>/dev/null; then

                echo "Creating placeholder secret: $SECRET_NAME"
                if ! CREATE_OUTPUT=$(AWS_ACCESS_KEY_ID="$TARGET_AWS_ACCESS_KEY_ID" \
                                     AWS_SECRET_ACCESS_KEY="$TARGET_AWS_SECRET_ACCESS_KEY" \
                                     AWS_SESSION_TOKEN="$TARGET_AWS_SESSION_TOKEN" \
                                     aws secretsmanager create-secret \
                                     --name "$SECRET_NAME" \
                                     --description "Placeholder secret for Maestro agent (created by buildspec)" \
                                     --secret-string '{"placeholder":true}' \
                                     --region ${TARGET_REGION} 2>&1); then

                    # Check if failure is due to secret already existing (race condition)
                    if echo "$CREATE_OUTPUT" | grep -q "ResourceExistsException"; then
                        echo "Secret $SECRET_NAME already exists (created concurrently)"
                    else
                        echo "❌ Failed to create secret $SECRET_NAME"
                        echo "Error: $CREATE_OUTPUT"
                        exit 1
                    fi
                else
                    echo "✓ Created secret $SECRET_NAME"
                fi
            else
                echo "Secret $SECRET_NAME already exists"
            fi
        done

        echo "Maestro agent placeholder secrets verified"
        echo ""

        # Restore central account credentials for Terraform backend access
        echo "Restoring central account credentials for Terraform backend access..."
        export AWS_ACCESS_KEY_ID="${CENTRAL_AWS_ACCESS_KEY_ID}"
        export AWS_SECRET_ACCESS_KEY="${CENTRAL_AWS_SECRET_ACCESS_KEY}"
        export AWS_SESSION_TOKEN="${CENTRAL_AWS_SESSION_TOKEN}"

        # Verify we're back to central account
        CURRENT_ACCOUNT=$(aws sts get-caller-identity --query Account --output text)
        echo "Current account: $CURRENT_ACCOUNT (central: $CENTRAL_ACCOUNT_ID)"
        echo ""

        # Run Infrastructure Provision (without ArgoCD bootstrap)
        echo "Running Infrastructure Provisioning..."

        # Export required environment variables for Makefile target
        # For management clusters, extract region_alias from generated terraform config
        MC_CONFIG_FILE="deploy/${ENVIRONMENT:-staging}/${TARGET_REGION}/terraform/management/${TARGET_ALIAS}.json"
        if [ ! -f "$MC_CONFIG_FILE" ]; then
            echo "❌ ERROR: Management cluster config not found: $MC_CONFIG_FILE"
            echo "   This file should be generated by scripts/render.py"
            exit 1
        fi

        export REGION_ALIAS=$(jq -r '.region_alias' "$MC_CONFIG_FILE")
        echo "Extracted REGION_ALIAS from config: $REGION_ALIAS"
        export ENVIRONMENT="${ENVIRONMENT:-staging}"

        set +e
        if [ "${IS_DESTROY:-false}" == "true" ]; then
            echo "⚠️ DESTRUCTION MODE ENABLED"
            make pipeline-destroy-management
        else
            make pipeline-provision-management
        fi
        PROVISION_STATUS=$?
        set -e

        if [ $PROVISION_STATUS -ne 0 ]; then
            echo "❌ Infrastructure action failed with exit code $PROVISION_STATUS"
            exit $PROVISION_STATUS
        fi

        echo "✅ Infrastructure action complete."
        if [ "${IS_DESTROY:-false}" == "true" ]; then
             echo "✅ Management cluster destroyed successfully."
        else
             echo "✅ Management cluster provisioned successfully."
        fi

  post_build:
    commands:
      - echo "Infrastructure deployment complete."
artifacts:
  files:
    - '**/*'
