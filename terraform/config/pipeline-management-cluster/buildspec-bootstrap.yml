version: 0.2

env:
  shell: bash

phases:
  install:
    commands:
      - echo "Installing dependencies for ArgoCD bootstrap..."
      - yum install -y jq gnupg2
      - chmod +x scripts/bootstrap-argocd.sh
      - echo "Installing kubectl..."
      - |
        set -euo pipefail
        KUBECTL_VERSION="v1.31.0"

        # Download kubectl binary and checksum
        echo "Downloading kubectl ${KUBECTL_VERSION}..."
        curl -sSfLO "https://dl.k8s.io/release/${KUBECTL_VERSION}/bin/linux/amd64/kubectl"
        curl -sSfLO "https://dl.k8s.io/release/${KUBECTL_VERSION}/bin/linux/amd64/kubectl.sha256"

        # Verify checksum
        echo "Verifying kubectl checksum..."
        if ! echo "$(cat kubectl.sha256)  kubectl" | sha256sum -c -; then
          echo "❌ kubectl checksum verification failed"
          exit 1
        fi
        echo "✓ kubectl checksum verified"

        # Install kubectl
        chmod +x kubectl
        mv kubectl /usr/local/bin/
        rm -f kubectl.sha256

        kubectl version --client
        echo "✓ kubectl installation verified"
      - echo "Installing Terraform (needed to read outputs)..."
      - |
        set -euo pipefail
        TF_VERSION="1.14.3"
        TF_PACKAGE="terraform_${TF_VERSION}_linux_amd64.zip"
        TF_BASE_URL="https://releases.hashicorp.com/terraform/${TF_VERSION}"

        # Download Terraform package and verification files
        echo "Downloading Terraform ${TF_VERSION}..."
        curl -sSfO "${TF_BASE_URL}/${TF_PACKAGE}"
        curl -sSfO "${TF_BASE_URL}/terraform_${TF_VERSION}_SHA256SUMS"
        curl -sSfO "${TF_BASE_URL}/terraform_${TF_VERSION}_SHA256SUMS.sig"

        # Import HashiCorp GPG key
        echo "Importing HashiCorp GPG key..."
        gpg --batch --keyserver keyserver.ubuntu.com --recv-keys \
          C874011F0AB405110D02105534365D9472D7468F || \
        gpg --batch --keyserver keys.openpgp.org --recv-keys \
          C874011F0AB405110D02105534365D9472D7468F || \
        gpg --batch --keyserver pgp.mit.edu --recv-keys \
          C874011F0AB405110D02105534365D9472D7468F

        # Verify GPG signature on SHA256SUMS
        echo "Verifying GPG signature..."
        if ! gpg --batch --verify "terraform_${TF_VERSION}_SHA256SUMS.sig" "terraform_${TF_VERSION}_SHA256SUMS"; then
          echo "❌ GPG signature verification failed"
          exit 1
        fi
        echo "✓ GPG signature verified"

        # Verify checksum of Terraform package
        echo "Verifying SHA256 checksum..."
        if ! grep "${TF_PACKAGE}" "terraform_${TF_VERSION}_SHA256SUMS" | sha256sum -c -; then
          echo "❌ Checksum verification failed"
          exit 1
        fi
        echo "✓ Checksum verified"

        # Install Terraform
        echo "Installing Terraform..."
        unzip -o "${TF_PACKAGE}" -d /tmp/tf-bin
        mv /tmp/tf-bin/terraform /usr/local/bin/

        # Cleanup
        rm -f "${TF_PACKAGE}" "terraform_${TF_VERSION}_SHA256SUMS" "terraform_${TF_VERSION}_SHA256SUMS.sig"

        terraform version
        echo "✓ Terraform installation verified"

  build:
    commands:
      - echo "=========================================="
      - echo "ArgoCD Bootstrap for Management Cluster"
      - echo "=========================================="
      - |
        set -euo pipefail

        # Function to assume role and export credentials with error handling
        assume_role_and_export_creds() {
            local ROLE_ARN=$1
            local SESSION_NAME=$2

            echo "Assuming role: $ROLE_ARN"

            # Capture both stdout and stderr
            local TEMP_FILE=$(mktemp)
            if ! TEMP_CREDS=$(aws sts assume-role \
                --role-arn "$ROLE_ARN" \
                --role-session-name "$SESSION_NAME" \
                --query 'Credentials.[AccessKeyId,SecretAccessKey,SessionToken]' \
                --output text 2>"$TEMP_FILE"); then
                echo "ERROR: Failed to assume role $ROLE_ARN" >&2
                echo "AWS CLI error output:" >&2
                cat "$TEMP_FILE" >&2
                rm -f "$TEMP_FILE"
                return 1
            fi
            rm -f "$TEMP_FILE"

            # Validate credentials are not empty
            if [ -z "$TEMP_CREDS" ]; then
                echo "ERROR: Received empty credentials from assume-role for $ROLE_ARN" >&2
                return 1
            fi

            # Safely parse credentials using read to avoid word-splitting
            read -r AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_SESSION_TOKEN <<< "$TEMP_CREDS"
            export AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_SESSION_TOKEN

            # Validate all three parts are present
            if [ -z "$AWS_ACCESS_KEY_ID" ] || [ -z "$AWS_SECRET_ACCESS_KEY" ] || [ -z "$AWS_SESSION_TOKEN" ]; then
                echo "ERROR: Failed to parse credentials from assume-role output for $ROLE_ARN" >&2
                echo "Credentials format may be invalid" >&2
                return 1
            fi

            echo "Successfully assumed role: $ROLE_ARN"
            return 0
        }

        # Function to ensure state bucket exists with proper security settings
        ensure_state_bucket() {
            local BUCKET_NAME=$1
            local BUCKET_REGION=$2
            local TARGET_ACCOUNT=$3

            echo "Ensuring state bucket exists: $BUCKET_NAME in account $TARGET_ACCOUNT"

            # Assume role in target account to create bucket
            if ! assume_role_and_export_creds \
                "arn:aws:iam::${TARGET_ACCOUNT}:role/OrganizationAccountAccessRole" \
                "terraform-state-bucket-creation"; then
                echo "ERROR: Cannot proceed without valid credentials for account $TARGET_ACCOUNT" >&2
                return 1
            fi

            # Check if bucket exists
            if ! aws s3api head-bucket --bucket "$BUCKET_NAME" 2>/dev/null; then
                echo "Creating state bucket $BUCKET_NAME in $BUCKET_REGION..."

                if [ "$BUCKET_REGION" == "us-east-1" ]; then
                    aws s3api create-bucket --bucket "$BUCKET_NAME" --region "$BUCKET_REGION"
                else
                    aws s3api create-bucket --bucket "$BUCKET_NAME" --region "$BUCKET_REGION" \
                        --create-bucket-configuration LocationConstraint="$BUCKET_REGION"
                fi

                # Enable versioning
                aws s3api put-bucket-versioning --bucket "$BUCKET_NAME" \
                    --versioning-configuration Status=Enabled

                # Enable encryption
                aws s3api put-bucket-encryption --bucket "$BUCKET_NAME" \
                    --server-side-encryption-configuration \
                    '{"Rules": [{"ApplyServerSideEncryptionByDefault": {"SSEAlgorithm": "AES256"}}]}'

                # Block public access
                aws s3api put-public-access-block --bucket "$BUCKET_NAME" \
                    --public-access-block-configuration \
                    "BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true"

                echo "✓ State bucket created and configured"
            else
                echo "✓ State bucket already exists"
            fi

            # Note: Credentials remain set for Terraform to use for S3 backend access
            echo "✓ Credentials configured for Terraform operations"
        }

        # Validate required environment variables
        if [[ -z "$TARGET_ACCOUNT_ID" || -z "$TARGET_REGION" || -z "$TARGET_ALIAS" ]]; then
            echo "❌ ERROR: Required environment variables not set"
            echo "   TARGET_ACCOUNT_ID: ${TARGET_ACCOUNT_ID}"
            echo "   TARGET_REGION: ${TARGET_REGION}"
            echo "   TARGET_ALIAS: ${TARGET_ALIAS}"
            exit 1
        fi

        echo "Target Account: ${TARGET_ACCOUNT_ID}"
        echo "Target Region: ${TARGET_REGION}"
        echo "Target Alias: ${TARGET_ALIAS}"
        echo "Target Environment: ${TARGET_ENVIRONMENT:-integration}"

        # Define role ARN for cross-account access
        ROLE_ARN="arn:aws:iam::${TARGET_ACCOUNT_ID}:role/OrganizationAccountAccessRole"

        # Set Terraform backend config (state stored in management account)
        export TF_STATE_BUCKET="terraform-state-${TARGET_ACCOUNT_ID}"
        export TF_STATE_KEY="management-cluster/${TARGET_ALIAS}.tfstate"
        export TF_STATE_REGION=$TARGET_REGION

        # Ensure state bucket exists in target account
        ensure_state_bucket "$TF_STATE_BUCKET" "$TF_STATE_REGION" "$TARGET_ACCOUNT_ID"

        # Generate override.tf for cross-account access
        echo "Generating override.tf for cross-account access..."
        echo 'provider "aws" {' > terraform/config/management-cluster/override.tf
        echo "  region = \"${TARGET_REGION}\"" >> terraform/config/management-cluster/override.tf
        echo '  assume_role {' >> terraform/config/management-cluster/override.tf
        echo "    role_arn = \"${ROLE_ARN}\"" >> terraform/config/management-cluster/override.tf
        echo '  }' >> terraform/config/management-cluster/override.tf
        echo '}' >> terraform/config/management-cluster/override.tf

        # Initialize Terraform to read state
        echo "Initializing Terraform to read outputs..."
        cd terraform/config/management-cluster
        terraform init -reconfigure \
            -backend-config="bucket=${TF_STATE_BUCKET}" \
            -backend-config="key=${TF_STATE_KEY}" \
            -backend-config="region=${TF_STATE_REGION}" \
            -backend-config="use_lockfile=true"
        cd ../../..

        # Export ASSUME_ROLE_ARN for bootstrap script
        export ASSUME_ROLE_ARN="${ROLE_ARN}"

        echo "Bootstrapping ArgoCD..."
        scripts/bootstrap-argocd.sh management-cluster "${TARGET_ENVIRONMENT:-integration}" "${TARGET_ALIAS}" "${TARGET_REGION}"

        # Cleanup
        echo "Cleaning up..."
        rm -f terraform/config/management-cluster/override.tf

        echo "✅ ArgoCD bootstrap complete!"
